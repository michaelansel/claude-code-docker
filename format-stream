#!/usr/bin/env python3
"""Format claude stream-json output into readable terminal output."""
import sys
import json
import os
import re
import signal
import threading
import queue
from datetime import datetime
from pathlib import Path
from typing import Optional

DIM = "\033[2m"
BOLD = "\033[1m"
CYAN = "\033[36m"
GREEN = "\033[32m"
YELLOW = "\033[33m"
MAGENTA = "\033[35m"
RESET = "\033[0m"

# Global log file handle
_log_file_handle: Optional[object] = None
_log_dir: Optional[Path] = None
_log_enabled: bool = True
_session_started: bool = False

def generate_log_filename() -> str:
    """Generate timestamp-based log filename."""
    return datetime.now().strftime("%Y-%m-%d_%H-%M-%S")

def setup_log_file(log_dir: Path) -> Optional[object]:
    """Setup log file with proper permissions.

    Args:
        log_dir: Directory to store log files

    Returns:
        File handle if logging is enabled, None otherwise
    """
    if not _log_enabled:
        return None

    try:
        # Create log directory with 0o700 permissions if it doesn't exist
        log_dir.mkdir(parents=True, exist_ok=True)
        os.chmod(log_dir, 0o700)

        # Generate filename with timestamp and PID for uniqueness
        timestamp = generate_log_filename()
        log_path = log_dir / f"{timestamp}.json"

        # Open log file in append mode
        log_file = open(log_path, 'a')

        # Set file permissions to 0o600 (read/write only for owner)
        os.chmod(log_path, 0o600)

        return log_file
    except Exception as e:
        sys.stderr.write(f"Error setting up log file: {e}\n", file=sys.stderr)
        return None

_log_queue: queue.Queue = queue.Queue(maxsize=1000)

def log_worker(log_file: object, q: queue.Queue):
    """Thread function: Read from queue and write to log file."""
    while True:
        line = q.get()
        if line is None:  # sentinel
            break
        try:
            log_file.write(line)
            log_file.flush()
        except Exception:
            pass
        q.task_done()

def format_event(data: dict) -> Optional[str]:
    """Process a parsed JSON event dict into display output."""
    t = data.get("type")
    sub = data.get("subtype", "")

    if t == "system" and sub == "hook_response":
        name = data.get("hook_name", "")
        output = data.get("output", "").strip()
        if output:
            return f"{DIM}[{name}]{RESET} {output}"

    if t == "system" and sub == "init":
        global _session_started
        mcp = [s["name"] for s in data.get("mcp_servers", []) if s.get("status") == "connected"]
        model = data.get("model", "")
        plugins = [p["name"] for p in data.get("plugins", [])]
        parts = [f"{DIM}model={model}{RESET}"]
        if mcp:
            parts.append(f"{DIM}mcp=[{', '.join(mcp)}]{RESET}")
        if plugins:
            parts.append(f"{DIM}plugins=[{', '.join(plugins)}]{RESET}")
        label = "▶ Session started" if not _session_started else "▶ Session resumed"
        _session_started = True
        return f"{CYAN}{label}{RESET}  {' '.join(parts)}"

    if t == "assistant":
        msg = data.get("message", {})
        contents = msg.get("content", [])
        parts = []
        for block in contents:
            if block.get("type") == "text" and block.get("text"):
                parts.append(f"{BOLD}{block['text']}{RESET}")
            elif block.get("type") == "tool_use":
                name = block.get("name", "")
                inp = block.get("input", {})
                # compact summary of tool input
                summary = ""
                if "command" in inp:
                    summary = inp["command"]
                elif "pattern" in inp:
                    summary = inp["pattern"]
                elif "file_path" in inp:
                    summary = inp["file_path"]
                elif "message" in inp:
                    summary = inp["message"][:80]
                elif "description" in inp:
                    summary = inp["description"][:80]
                elif "prompt" in inp:
                    summary = inp["prompt"][:80]
                elif "query" in inp:
                    summary = inp["query"][:80]
                elif "skill" in inp:
                    summary = inp["skill"]
                elif "to" in inp:
                    summary = f"→ {inp['to']}: {inp.get('response', inp.get('message', ''))[:60]}"

                if summary:
                    parts.append(f"{YELLOW}⚡ {name}{RESET} {DIM}{summary}{RESET}")
                else:
                    parts.append(f"{YELLOW}⚡ {name}{RESET}")
        if parts:
            return "\n".join(parts)

    if t == "user" and data.get("tool_use_result"):
        result = data["tool_use_result"]
        if isinstance(result, str):
            content = result
        else:
            if "stdout" in result or "stderr" in result:
                content = (result.get("stdout") or result.get("stderr") or "").strip()
                if result.get("noOutputExpected") and not content:
                    return None
            else:
                content = result.get("content", "")
        if isinstance(content, list):
            # content can be a list of blocks like [{"type": "text", "text": "..."}]
            content = " ".join(b.get("text", "") for b in content if isinstance(b, dict))
        if not isinstance(content, str):
            content = str(content)
        if len(content) > 200:
            content = content[:200] + "..."
        if content:
            return f"{GREEN}  ↳ {content}{RESET}"

    if t == "user" and not data.get("tool_use_result"):
        msg_content = data.get("message", {}).get("content", [])
        if isinstance(msg_content, list):
            for block in msg_content:
                if isinstance(block, dict):
                    if block.get("type") == "tool_result":
                        raw = block.get("content", "")
                        if isinstance(raw, list):
                            raw = " ".join(b.get("text", "") for b in raw if isinstance(b, dict))
                        if not isinstance(raw, str):
                            raw = str(raw)
                        if len(raw) > 200:
                            raw = raw[:200] + "..."
                        if raw and not block.get("is_error"):
                            return f"{GREEN}  ↳ {raw}{RESET}"
                    elif block.get("type") == "text" and block.get("text"):
                        text = block["text"].strip()
                        if len(text) > 200:
                            text = text[:200] + "..."
                        return f"{DIM}[user] {text}{RESET}"

    if t == "system" and sub == "hook_started":
        name = data.get("hook_name", "")
        return f"{DIM}[{name}] starting...{RESET}"

    if t == "result":
        result = data.get("result", "")
        try:
            cost = float(data.get("total_cost_usd", 0) or 0)
        except (TypeError, ValueError):
            cost = 0.0
        turns = data.get("num_turns", 0)
        status = f"{DIM}(turns={turns} cost=${cost:.4f}){RESET}"
        if sub == "success":
            return f"\n{CYAN}■ Done{RESET} {status}\n{result}"
        elif sub == "error_during_execution":
            errors = data.get("errors", [])
            err_msg = errors[0] if errors else "unknown error"
            return f"\n{MAGENTA}■ Error{RESET} {status}\n{err_msg}"

    return None

def format_line(line: str) -> Optional[str]:
    line = line.strip()
    if not line:
        return None

    try:
        data = json.loads(line)
    except json.JSONDecodeError:
        if line.startswith('{'):
            # Possibly truncated+concatenated — scan for embedded valid objects
            results = []
            for m in re.finditer(r'\{"type":', line):
                if m.start() == 0:
                    continue  # skip the known-invalid first object
                try:
                    obj, _ = json.JSONDecoder().raw_decode(line, m.start())
                    out = format_event(obj)
                    if out:
                        results.append(out)
                except json.JSONDecodeError:
                    pass
            return '\n'.join(results) if results else None
        # Non-JSON: show short messages (Docker errors etc), suppress long fragments
        return line if len(line) < 200 else None

    if not isinstance(data, dict):
        return None
    return format_event(data)

def cleanup_on_exit(signum=None, frame=None):
    """Cleanup: Close log file handle on exit."""
    global _log_file_handle
    if _log_file_handle is not None:
        try:
            _log_file_handle.close()
            sys.stderr.write(f"[format-stream] Log file closed.\n", file=sys.stderr)
        except Exception:
            pass
        _log_file_handle = None

# Register signal handlers for cleanup
signal.signal(signal.SIGINT, cleanup_on_exit)
signal.signal(signal.SIGTERM, cleanup_on_exit)

# Read configuration from DOCKER_YAML_CONFIG
try:
    DOCKER_YAML_CONFIG_PATH = Path.home() / ".claude-docker" / "claude-docker.yaml"
    if DOCKER_YAML_CONFIG_PATH.exists():
        try:
            import yaml
            with open(DOCKER_YAML_CONFIG_PATH) as f:
                config = yaml.safe_load(f) or {}
                stream_log_config = config.get("streamLogging", {})
                _log_enabled = stream_log_config.get("enabled", True)
                _log_dir = Path(stream_log_config.get("directory", str(Path.home() / ".claude-docker" / "session-logs")))
        except ImportError:
            # PyYAML not available, use defaults
            _log_enabled = True
            _log_dir = Path.home() / ".claude-docker" / "session-logs"
    else:
        # Default config
        _log_enabled = True
        _log_dir = Path.home() / ".claude-docker" / "session-logs"
except Exception:
    # If config reading fails, use defaults
    _log_enabled = True
    _log_dir = Path.home() / ".claude-docker" / "session-logs"

# Setup log file if enabled
_log_file_handle = setup_log_file(_log_dir)

# Main loop: read stdin, queue for logging, format for display
if _log_file_handle is not None:
    log_thread = threading.Thread(target=log_worker, args=(_log_file_handle, _log_queue), daemon=True)
    log_thread.start()
    try:
        for line in sys.stdin:
            _log_queue.put(line)
            try:
                out = format_line(line)
                if out is not None:
                    print(out, flush=True)
            except Exception:
                pass
    finally:
        _log_queue.put(None)  # sentinel to stop log thread
        log_thread.join(timeout=2)
        cleanup_on_exit()
else:
    for line in sys.stdin:
        try:
            out = format_line(line)
            if out is not None:
                print(out, flush=True)
        except Exception:
            pass
